= ğŸ§—EntraÃ®nement de l'agent
:imagesdir: assets/default/images
image::mi-training.png[]
//mi-2

== Terrain dâ€™exercice : KinD

* Un seul serveur
* Docker

image::kind-logo.png[width=45%]

[NOTE.speaker]
====
Distribution Kubernetes
* Kubernetes IN Docker

ğŸ“ Pourquoi Kind ?
* ğŸ” Rapide Ã  dÃ©ployer
* ğŸ› ï¸ IdÃ©al pour les tests et les expÃ©rimentations
====

== CI/CD : GitHub Action

image::github-action.png[]

[NOTE.speaker]
====
* Mission rÃ©pÃ©table Ã  volontÃ©
* Automatisation totale
  *  Chaque commit, chaque PR, dÃ©clenche un test de dÃ©ploiement
* "Gratuit"
* VM temporaires avec 4 CPU pour simuler des missions
* Tests en environnement contrÃ´lÃ©
====

== Infrastructure as code

* Terraform / Opentofu
* Pulumi
* Crossplane

[NOTE.speaker]
====
ğŸ§­ Mission : CrÃ©er, gÃ©rer et Ã©liminer 511 clustersâ€¦ sans faille.

ğŸ¯ Objectif : Choisir l'outil idÃ©al pour des dÃ©ploiements

ğŸ§° Options du QG :
  * Terraform / Opentofu
  * Pulumi
  * Crossplane

ğŸ•¶ï¸ DÃ©cision :
  * Pulumi
====

== Pulumi

[source,python,linenums]
----
kind = local.Command("kindCluster",
    create="kind create cluster --config kind.yaml --name cmesh1"
)

kind2 = local.Command("kindCluster2",
    create="kind create cluster --config kind-2.yaml --name cmesh2"
)

cmesh1_provider = cilium.Provider("cmesh1", context="kind-cmesh1", opts=pulumi.ResourceOptions(depends_on=[kind]))
cmesh2_provider = cilium.Provider("cmesh2", context="kind-cmesh2", opts=pulumi.ResourceOptions(depends_on=[kind2]))

cmesh1_cilium = cilium.Install("cmesh1Install",
    sets=[
        "cluster.name=cmesh1",
        "cluster.id=1",
        "ipam.mode=kubernetes",
    ],
    version="1.15.5",
    opts=pulumi.ResourceOptions(depends_on=[kind], providers=[cmesh1_provider]),
)

cmesh2_cilium = cilium.Install("cmesh2Install",
    sets=[
        "cluster.name=cmesh2",
        "cluster.id=2",
        "ipam.mode=kubernetes",
    ],
    version="1.15.5",
    opts=pulumi.ResourceOptions(depends_on=[kind2], providers=[cmesh2_provider]),
)

cmesh1_cmeshenable = cilium.Clustermesh("cmesh1Enable", service_type="NodePort", opts=pulumi.ResourceOptions(depends_on=[cmesh1_cilium], providers=[cmesh1_provider]))
cmesh2_cmeshenable = cilium.Clustermesh("cmesh2Enable", service_type="NodePort", opts=pulumi.ResourceOptions(depends_on=[cmesh2_cilium], providers=[cmesh2_provider]))

cilium.ClustermeshConnection("cmeshConnect", destination_context="kind-cmesh2", opts=pulumi.ResourceOptions(depends_on=[cmesh1_cmeshenable], providers=[cmesh1_provider]))
----


[NOTE.speaker]
====
* Infra as real code
* Python
====

== Limite de KinD

Combien de clusters Kubernetes peut-on crÃ©er ?

[NOTE.speaker]
====
ğŸ›ï¸ MatÃ©riel utilisÃ© :
  * ğŸ–¥ï¸ 16 CPU â€” ğŸ§  32 Go de RAM

ğŸš« RÃ©sultat :
  * Blocage Ã  15 clusters maximum
  * Temps de dÃ©ploiement : 45 minutes

ğŸ’£ Bien trop long pour 511 clusters.
====
